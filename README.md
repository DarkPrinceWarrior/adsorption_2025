# Adsorbent Inverse Design Framework (2025)

## Аннотация
Данный репозиторий реализует систему **обратного дизайна (Inverse Design)** пористых металл-органических каркасов (MOF). Система решает фундаментальную проблему материаловедения: поиск оптимальных условий синтеза для получения материала с заранее заданными структурно-энергетическими характеристиками (СЭХ).

В основе подхода лежит гибридная архитектура:
1.  **Deep Ensemble Forward Model:** Ансамбль градиентных бустингов (CatBoost) для предсказания свойств материала по условиям синтеза с оценкой эпистемической неопределенности (Uncertainty Quantification).
2.  **Bayesian Optimization (Navigator):** Использование алгоритма Tree-structured Parzen Estimator (TPE) для навигации в пространстве химических реакций и поиска рецепта, удовлетворяющего критериям пользователя.

---

## 1. Методология

### Прямая задача (Forward Problem)
Мы моделируем функцию $f: \text{Synthesis} \to \text{Properties}$.
*   **Входные данные ($X$):** 
    *   *Химические реагенты:* Тип металла, тип лиганда, растворитель.
    *   *Физико-химические дескрипторы металла:* Ионный радиус, степень окисления, электронное сродство, HSAB жёсткость, эффект Яна-Теллера.
    *   *Дескрипторы лиганда:* Молекулярная масса, число карбоксильных групп, TPSA.
    *   *Параметры процесса:* Температуры синтеза, сушки и активации ($T_{syn}, T_{dry}, T_{act}$), стехиометрические соотношения (Metal/Ligand ratio), концентрации.
*   **Целевые переменные ($Y$) — актуальная тройка (W0 и $S_{BET}$ больше не предсказываем):**
    *   $E_0$ [кДж/моль] — Характеристическая энергия адсорбции.
    *   $S_{me}$ [м²/г] — Удельная поверхность мезопор (важно для транспортных свойств).
    *   $x_0$ [нм] — Характеристическая полуширина пор.

### Оценка неопределенности (Uncertainty Quantification)
Вместо точечного прогноза, система выдает распределение $P(y|x)$. Мы используем ансамбль из 5 моделей, обученных с различной инициализацией и стратификацией данных.
*   **Среднее значение ($\mu$):** Наиболее вероятное свойство.
*   **Стандартное отклонение ($\sigma$):** Мера уверенности модели. Если рецепт находится в "неизведанной" области химического пространства, $\sigma$ возрастает, что позволяет отфильтровывать ненадежные прогнозы.

---

## 2. Установка и Настройка

Требуется Python 3.10+. Зависимости зафиксированы в `requirements.txt` (scikit-learn≥1.2, imbalanced-learn≥0.11).

```bash
# 1. Создание виртуального окружения
python3 -m venv venv
source venv/bin/activate

# 2. Установка зависимостей
pip install -r requirements.txt

# 3. Запуск тестов (40 тестов)
PYTHONPATH=src python -m pytest tests/ -q
```

---

## 3. Руководство пользователя (Workflow)

### Этап I: Обучение модели (Training)
Система обучается на экспериментальных данных с **продвинутым отбором признаков**:
1. **Удаление мультиколлинеарности:** Автоматически убираются фичи с корреляцией |r| > 0.85 и VIF > 10.
2. **Domain Knowledge:** Используется экспертная фильтрация физически обоснованных дескрипторов.
3. **Permutation Importance:** Финальный отбор топ-15 фич по важности.

```bash
PYTHONPATH=src python scripts/train_forward_model.py \
    --data data/SEC_SYN_with_features_enriched.csv \
    --iterations 1000 \
    --validation-mode warn  # strict -> остановится на неконсистентных строках
```
Если у вас только базовый датасет `data/SEC_SYN_with_features.csv`, сначала обогатите его дескрипторами:
```bash
PYTHONPATH=src python scripts/enrich_descriptors.py \
    --input data/SEC_SYN_with_features.csv \
    --output data/SEC_SYN_with_features_enriched.csv
```
*Результат:* В папке `artifacts/forward_models` создаются 5 ансамблей (по одному на каждое целевое свойство).

### Этап II: Валидация (Validation)
Перед использованием рекомендуется проверить надежность моделей. Скрипт строит **Rejection Plots**, показывая, как падает ошибка (MAE) при отсеве неуверенных прогнозов.

```bash
PYTHONPATH=src python scripts/validate_uncertainty.py
```
*Результат:* Графики в `artifacts/plots/uncertainty_rejection_plots.png`.
*Метрики (5-fold OOF CV, см. `artifacts/forward_models/metrics.json`):*
*   **$x_0$:** $R^2 \approx 0.82$
*   **$E_0$:** $R^2 \approx 0.79$
*   **$S_{me}$:** $R^2 \approx 0.79$
Строгая валидация (`--validation-mode strict`) на текущем датасете падает из-за неконсистентных температур/стехиометрии; по умолчанию используйте `warn` или очистите данные.

### Этап III: Поиск рецепта (Inverse Design)
Основной инструмент исследователя. Вы задаете желаемые СЭХ, а алгоритм ищет оптимальные условия синтеза.

**Пример запроса:** Найти материал с высокой энергией адсорбции ($E_0 \approx 29.3$), подходящим размером пор ($x_0 \approx 0.41$) и развитой мезопористостью ($S_{me} \approx 82$).

```bash
PYTHONPATH=src python scripts/run_bayes_opt.py \
    --E0 29.3 \
    --x0 0.41 \
    --Sme 82 \
    --trials 300
```

**Аргументы (цели):**
*   `--E0`, `--x0`, `--Sme`: целевые значения свойств.
*   `--trials`: количество итераций поиска (рекомендуется 200-500).

*Результат:* Файл `predictions_bo.csv` с ранжированным списком рецептов.
В файле указаны не только условия синтеза (Металл, Лиганд, $T_{syn}$), но и предсказанная **неопределенность** ($\sigma$). Выбирайте рецепты с низким значением `Pred_Uncertainty`.

---

## 4. Структура проекта

```
├── scripts/
│   ├── train_forward_model.py  # Обучение Deep Ensembles
│   ├── validate_uncertainty.py # Оценка качества и калибровка
│   ├── run_bayes_opt.py        # Inverse Design (Поиск рецептов)
│   ├── generate_paper_figures.py # Фигуры для статьи/отчета
│   └── enrich_descriptors.py   # Обогащение датасета (RDKit + коорд. химия)
├── src/
│   └── adsorb_synthesis/
│       ├── data_processing.py    # Генерация дескрипторов (inplace=True/False)
│       ├── data_validation.py    # Валидация физических ограничений
│       ├── feature_selection.py  # Advanced Feature Selection (VIF, корреляции)
│       ├── physics_losses.py     # Физические constraints и penalties
│       ├── constants.py          # Справочники (Molar Masses, Features)
│       └── ...
├── tests/                        # Базовые unit-тесты
├── data/                         # Экспериментальные датасеты
└── artifacts/                    # Сохраненные модели и графики
```

## 5. Особенности реализации

### Advanced Feature Selection
Для каждого таргета автоматически:
1. Удаляются высококоррелированные фичи (|r| > 0.85)
2. Итеративно убираются фичи с VIF > 10 (мультиколлинеарность)
3. Ранжирование по Permutation Importance
4. Отбор топ-15 фич с учётом domain knowledge

### Физико-химические дескрипторы
Модель использует продвинутые дескрипторы:
*   **Металл:** `ionic_radius_pm`, `electron_affinity_kj`, `oxidation_state`, `Jahn_Teller_Active`
*   **Лиганд:** `carboxyl_groups`, `molecular_weight`
*   **Взаимодействие:** `Metal_Ligand_Size_Ratio`

### Валидация данных
`validate_synthesis_data` поддерживает режимы `warn`/`strict`. Текущий датасет содержит строки с нарушением температурного порядка, точек кипения и стехиометрии, поэтому строгий режим приведет к ошибке загрузки — используйте `warn`, либо предварительно очистите данные.

### Data Processing Safety
Все функции мутации DataFrame поддерживают параметр `inplace`:
```python
# Безопасная копия (не мутирует оригинал)
df_new = add_salt_mass_features(df, inplace=False)

# Мутация на месте (по умолчанию, backward compatible)
add_salt_mass_features(df)  # inplace=True
```

### Прочее
*   **Physicochemical Constraints:** Оптимизатор учитывает жесткие ограничения (температурная монотонность, стехиометрия, точки кипения растворителей).
*   **Physics Penalties:** Sample weights увеличиваются для образцов с нарушениями физических constraints ($a_0 = 28.86 \cdot W_0$, $E = E_0/3$).
*   **Robustness:** `CatBoost` эффективно работает с категориальными данными без One-Hot кодирования.
*   **Uncertainty Quantification:** Ансамбль из 5 моделей даёт оценку неопределённости ($\sigma$).

---

## 6. Тестирование

```bash
# Все тесты
PYTHONPATH=src python -m pytest tests/ -v
```

**Покрытие:** базовые юнит-тесты по валидации данных, инженерии признаков и расчёту молярных масс.
